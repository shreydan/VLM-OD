{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db10262e-2b47-472e-aa35-1a11bbbfc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcfba6d-60ec-42c4-b054-b7d1e1c5301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e9cd8c8ca8463bae587fdbf36f61ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "moondream.py:   0%|          | 0.00/26.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d6d7cb46f742af86cce9b186e7882d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e392f67b8a84f508901d2eb726c56d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9ed035d30d410cbe072102df03ae24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"vikhyatk/moondream2\",\n",
    "    revision=\"2025-04-14\",\n",
    "    trust_remote_code=True,\n",
    "    # Uncomment to run on GPU.\n",
    "    device_map={\"\": \"cuda\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf2e00b7-87a8-463d-9efe-954b28844981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (coord_encoder): Linear(in_features=256, out_features=2048, bias=True)\n",
       "  (coord_decoder): ModuleDict(\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "  )\n",
       "  (size_encoder): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (size_decoder): ModuleDict(\n",
       "    (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e747ba2-14cb-4e7d-baaa-9ae95a9f5aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prefix': [198, 198, 47504, 25], 'suffix': [628]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.config.tokenizer.templates['detect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b96c1a6-fe4c-48ec-98b2-64bcdce6b8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":50256, \"content\":\"<|endoftext|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":50257, \"content\":\"                               \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50258, \"content\":\"                              \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50259, \"content\":\"                             \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50260, \"content\":\"                            \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50261, \"content\":\"                           \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50262, \"content\":\"                          \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50263, \"content\":\"                         \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50264, \"content\":\"                        \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50265, \"content\":\"                       \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50266, \"content\":\"                      \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50267, \"content\":\"                     \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50268, \"content\":\"                    \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50269, \"content\":\"                   \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50270, \"content\":\"                  \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50271, \"content\":\"                 \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50272, \"content\":\"                \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50273, \"content\":\"               \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50274, \"content\":\"              \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50275, \"content\":\"             \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50276, \"content\":\"            \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50277, \"content\":\"           \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50278, \"content\":\"          \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50279, \"content\":\"         \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50280, \"content\":\"        \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50281, \"content\":\"       \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50282, \"content\":\"      \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50283, \"content\":\"     \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50284, \"content\":\"    \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50285, \"content\":\"   \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50286, \"content\":\"  \", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50287, \"content\":\"\t\t\t\t\t\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50288, \"content\":\"\t\t\t\t\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50289, \"content\":\"\t\t\t\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50290, \"content\":\"\t\t\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50291, \"content\":\"\t\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50292, \"content\":\"\t\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50293, \"content\":\"\t\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}, {\"id\":50294, \"content\":\"\t\t\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":True, \"special\":False}], normalizer=None, pre_tokenizer=ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True), post_processor=ByteLevel(add_prefix_space=True, trim_offsets=False, use_regex=True), decoder=ByteLevel(add_prefix_space=True, trim_offsets=True, use_regex=True), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=\"\", end_of_word_suffix=\"\", fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"!\":0, \"\"\":1, \"#\":2, \"$\":3, \"%\":4, \"&\":5, \"'\":6, \"(\":7, \")\":8, \"*\":9, \"+\":10, \",\":11, \"-\":12, \".\":13, \"/\":14, \"0\":15, \"1\":16, \"2\":17, \"3\":18, \"4\":19, \"5\":20, \"6\":21, \"7\":22, \"8\":23, \"9\":24, \":\":25, \";\":26, \"<\":27, \"=\":28, \">\":29, \"?\":30, \"@\":31, \"A\":32, \"B\":33, \"C\":34, \"D\":35, \"E\":36, \"F\":37, \"G\":38, \"H\":39, \"I\":40, \"J\":41, \"K\":42, \"L\":43, \"M\":44, \"N\":45, \"O\":46, \"P\":47, \"Q\":48, \"R\":49, \"S\":50, \"T\":51, \"U\":52, \"V\":53, \"W\":54, \"X\":55, \"Y\":56, \"Z\":57, \"[\":58, \"\\\":59, \"]\":60, \"^\":61, \"_\":62, \"`\":63, \"a\":64, \"b\":65, \"c\":66, \"d\":67, \"e\":68, \"f\":69, \"g\":70, \"h\":71, \"i\":72, \"j\":73, \"k\":74, \"l\":75, \"m\":76, \"n\":77, \"o\":78, \"p\":79, \"q\":80, \"r\":81, \"s\":82, \"t\":83, \"u\":84, \"v\":85, \"w\":86, \"x\":87, \"y\":88, \"z\":89, \"{\":90, \"|\":91, \"}\":92, \"~\":93, \"¡\":94, \"¢\":95, \"£\":96, \"¤\":97, \"¥\":98, ...}, merges=[(\"Ġ\", \"t\"), (\"Ġ\", \"a\"), (\"h\", \"e\"), (\"i\", \"n\"), (\"r\", \"e\"), (\"o\", \"n\"), (\"Ġt\", \"he\"), (\"e\", \"r\"), (\"Ġ\", \"s\"), (\"a\", \"t\"), (\"Ġ\", \"w\"), (\"Ġ\", \"o\"), (\"e\", \"n\"), (\"Ġ\", \"c\"), (\"i\", \"t\"), (\"i\", \"s\"), (\"a\", \"n\"), (\"o\", \"r\"), (\"e\", \"s\"), (\"Ġ\", \"b\"), (\"e\", \"d\"), (\"Ġ\", \"f\"), (\"in\", \"g\"), (\"Ġ\", \"p\"), (\"o\", \"u\"), (\"Ġa\", \"n\"), (\"a\", \"l\"), (\"a\", \"r\"), (\"Ġt\", \"o\"), (\"Ġ\", \"m\"), (\"Ġo\", \"f\"), (\"Ġ\", \"in\"), (\"Ġ\", \"d\"), (\"Ġ\", \"h\"), (\"Ġan\", \"d\"), (\"i\", \"c\"), (\"a\", \"s\"), (\"l\", \"e\"), (\"Ġt\", \"h\"), (\"i\", \"on\"), (\"o\", \"m\"), (\"l\", \"l\"), (\"en\", \"t\"), (\"Ġ\", \"n\"), (\"Ġ\", \"l\"), (\"s\", \"t\"), (\"Ġ\", \"re\"), (\"v\", \"e\"), (\"Ġ\", \"e\"), (\"r\", \"o\"), (\"l\", \"y\"), (\"Ġb\", \"e\"), (\"Ġ\", \"g\"), (\"Ġ\", \"T\"), (\"c\", \"t\"), (\"Ġ\", \"S\"), (\"i\", \"d\"), (\"o\", \"t\"), (\"Ġ\", \"I\"), (\"u\", \"t\"), (\"e\", \"t\"), (\"Ġ\", \"A\"), (\"Ġ\", \"is\"), (\"Ġ\", \"on\"), (\"i\", \"m\"), (\"a\", \"m\"), (\"o\", \"w\"), (\"a\", \"y\"), (\"a\", \"d\"), (\"s\", \"e\"), (\"Ġth\", \"at\"), (\"Ġ\", \"C\"), (\"i\", \"g\"), (\"Ġf\", \"or\"), (\"a\", \"c\"), (\"Ġ\", \"y\"), (\"v\", \"er\"), (\"u\", \"r\"), (\"Ġ\", \"u\"), (\"l\", \"d\"), (\"Ġs\", \"t\"), (\"Ġ\", \"M\"), (\"'\", \"s\"), (\"Ġ\", \"he\"), (\"Ġ\", \"it\"), (\"at\", \"ion\"), (\"it\", \"h\"), (\"i\", \"r\"), (\"c\", \"e\"), (\"Ġy\", \"ou\"), (\"i\", \"l\"), (\"Ġ\", \"B\"), (\"Ġw\", \"h\"), (\"o\", \"l\"), (\"Ġ\", \"P\"), (\"Ġw\", \"ith\"), (\"Ġ\", \"1\"), (\"t\", \"er\"), (\"c\", \"h\"), ...]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e2a0d8-72d4-4614-af8c-485ca3fdc764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nDetect:'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.tokenizer.decode([198, 198, 47504, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "238028e5-16ce-48ff-bc5d-0e2d598817fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.tokenizer.decode([628])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa38e60b-f527-4ce6-a583-93e7cefe1bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "model.model.detect(\n",
       "    image: Union[PIL.Image.Image, transformers_modules.vikhyatk.moondream2\u001b[32m.797e1\u001b[39me4728e49ce676920e72e42cd0cb3948f504.moondream.EncodedImage],\n",
       "    object: str,\n",
       "    settings: Optional[transformers_modules.vikhyatk.moondream2\u001b[32m.797e1\u001b[39me4728e49ce676920e72e42cd0cb3948f504.moondream.ObjectSamplingSettings] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m <no docstring>\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "    \u001b[38;5;28;01mdef\u001b[39;00m detect(\n",
       "        self,\n",
       "        image: Union[Image.Image, EncodedImage],\n",
       "        object: str,\n",
       "        settings: Optional[ObjectSamplingSettings] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ):\n",
       "        \u001b[38;5;28;01mif\u001b[39;00m self.config.tokenizer.templates[\u001b[33m\"detect\"\u001b[39m] \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "            \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError(\u001b[33m\"Model does not support object detection.\"\u001b[39m)\n",
       "\n",
       "        image = self.encode_image(image)\n",
       "        self.load_encoded_image(image)\n",
       "\n",
       "        prompt_tokens = torch.tensor(\n",
       "            [\n",
       "                self.config.tokenizer.templates[\u001b[33m\"detect\"\u001b[39m][\u001b[33m\"prefix\"\u001b[39m]\n",
       "                + self.tokenizer.encode(\u001b[33m\" \"\u001b[39m + object).ids\n",
       "                + self.config.tokenizer.templates[\u001b[33m\"detect\"\u001b[39m][\u001b[33m\"suffix\"\u001b[39m]\n",
       "            ],\n",
       "            device=self.device,\n",
       "        )\n",
       "\n",
       "        _, hidden, next_token, pos = self._prefill_prompt(\n",
       "            prompt_tokens, image.pos, temperature=\u001b[32m0\u001b[39m, top_p=\u001b[32m0\u001b[39m\n",
       "        )\n",
       "        hidden = hidden[:, -\u001b[32m1\u001b[39m:, :]\n",
       "\n",
       "        max_objects = (\n",
       "            settings.get(\u001b[33m\"max_objects\"\u001b[39m, DEFAULT_MAX_OBJECTS)\n",
       "            \u001b[38;5;28;01mif\u001b[39;00m settings\n",
       "            \u001b[38;5;28;01melse\u001b[39;00m DEFAULT_MAX_OBJECTS\n",
       "        )\n",
       "        objects = self._generate_points(\n",
       "            hidden, next_token, pos, include_size=\u001b[38;5;28;01mTrue\u001b[39;00m, max_objects=max_objects\n",
       "        )\n",
       "\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"objects\"\u001b[39m: objects}\n",
       "\u001b[31mFile:\u001b[39m      /data2/shreyas/ENVS/HF_HOME/modules/transformers_modules/vikhyatk/moondream2/797e1e4728e49ce676920e72e42cd0cb3948f504/moondream.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model.detect??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7a227-1123-4359-9e03-d7c7dfd76684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db23af8d-cf36-40ce-95f9-05fb8dc9a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "model.model._generate_points(\n",
       "    hidden: torch.Tensor,\n",
       "    next_token: torch.Tensor,\n",
       "    pos: int,\n",
       "    include_size: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "    max_objects: int = \u001b[32m50\u001b[39m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m <no docstring>\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "    \u001b[38;5;28;01mdef\u001b[39;00m _generate_points(\n",
       "        self,\n",
       "        hidden: torch.Tensor,\n",
       "        next_token: torch.Tensor,\n",
       "        pos: int,\n",
       "        include_size: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "        max_objects: int = DEFAULT_MAX_OBJECTS,\n",
       "    ):\n",
       "        out = []\n",
       "        mask = torch.zeros(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2048\u001b[39m, device=self.device, dtype=torch.bool)\n",
       "        mask[:, :, :pos] = \u001b[32m1\u001b[39m\n",
       "        pos_ids = torch.tensor([pos], device=self.device, dtype=torch.long)\n",
       "\n",
       "        \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n",
       "            \u001b[38;5;28;01mwhile\u001b[39;00m (\n",
       "                next_token.item() != self.config.tokenizer.eos_id\n",
       "                \u001b[38;5;28;01mand\u001b[39;00m len(out) < max_objects\n",
       "            ):\n",
       "                x_logits = decode_coordinate(hidden, self.region)\n",
       "                x_center = torch.argmax(x_logits, dim=-\u001b[32m1\u001b[39m) / x_logits.size(-\u001b[32m1\u001b[39m)\n",
       "                next_emb = encode_coordinate(\n",
       "                    x_center.to(dtype=x_logits.dtype), self.region\n",
       "                ).unsqueeze(\u001b[32m0\u001b[39m)\n",
       "\n",
       "                \u001b[38;5;66;03m# Decode y-coordinate\u001b[39;00m\n",
       "                mask[:, :, pos], pos_ids[\u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m, pos\n",
       "                _, hidden = self._decode_one_tok(next_emb, mask, pos_ids)\n",
       "                pos += \u001b[32m1\u001b[39m\n",
       "                y_logits = decode_coordinate(hidden, self.region)\n",
       "                y_center = torch.argmax(y_logits, dim=-\u001b[32m1\u001b[39m) / y_logits.size(-\u001b[32m1\u001b[39m)\n",
       "                next_emb = encode_coordinate(\n",
       "                    y_center.to(dtype=y_logits.dtype), self.region\n",
       "                ).unsqueeze(\u001b[32m0\u001b[39m)\n",
       "\n",
       "                \u001b[38;5;66;03m# Decode size\u001b[39;00m\n",
       "                \u001b[38;5;28;01mif\u001b[39;00m include_size:\n",
       "                    mask[:, :, pos], pos_ids[\u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m, pos\n",
       "                    logits, hidden = self._decode_one_tok(next_emb, mask, pos_ids)\n",
       "                    pos += \u001b[32m1\u001b[39m\n",
       "                    size_logits = decode_size(hidden, self.region)\n",
       "\n",
       "                    \u001b[38;5;66;03m# Get bin indices from the logits\u001b[39;00m\n",
       "                    w_bin = torch.argmax(size_logits[\u001b[32m0\u001b[39m], dim=-\u001b[32m1\u001b[39m)\n",
       "                    h_bin = torch.argmax(size_logits[\u001b[32m1\u001b[39m], dim=-\u001b[32m1\u001b[39m)\n",
       "\n",
       "                    \u001b[38;5;66;03m# Convert from bin indices to actual size values using the inverse of the log-scale mapping\u001b[39;00m\n",
       "                    \u001b[38;5;66;03m# Formula: size = 2^((bin / 1023.0) * 10.0 - 10.0)\u001b[39;00m\n",
       "                    w = torch.pow(\u001b[32m2.0\u001b[39m, (w_bin.float() / \u001b[32m1023.0\u001b[39m) * \u001b[32m10.0\u001b[39m - \u001b[32m10.0\u001b[39m)\n",
       "                    h = torch.pow(\u001b[32m2.0\u001b[39m, (h_bin.float() / \u001b[32m1023.0\u001b[39m) * \u001b[32m10.0\u001b[39m - \u001b[32m10.0\u001b[39m)\n",
       "\n",
       "                    next_emb = (\n",
       "                        encode_size(\n",
       "                            torch.tensor(\n",
       "                                [w, h], device=self.device, dtype=size_logits.dtype\n",
       "                            ),\n",
       "                            self.region,\n",
       "                        )\n",
       "                        .unsqueeze(\u001b[32m0\u001b[39m)\n",
       "                        .unsqueeze(\u001b[32m0\u001b[39m)\n",
       "                    )\n",
       "\n",
       "                    \u001b[38;5;66;03m# Add object\u001b[39;00m\n",
       "                    out.append(\n",
       "                        {\n",
       "                            \u001b[33m\"x_min\"\u001b[39m: x_center.item() - w.item() / \u001b[32m2\u001b[39m,\n",
       "                            \u001b[33m\"y_min\"\u001b[39m: y_center.item() - h.item() / \u001b[32m2\u001b[39m,\n",
       "                            \u001b[33m\"x_max\"\u001b[39m: x_center.item() + w.item() / \u001b[32m2\u001b[39m,\n",
       "                            \u001b[33m\"y_max\"\u001b[39m: y_center.item() + h.item() / \u001b[32m2\u001b[39m,\n",
       "                        }\n",
       "                    )\n",
       "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "                    out.append({\u001b[33m\"x\"\u001b[39m: x_center.item(), \u001b[33m\"y\"\u001b[39m: y_center.item()})\n",
       "\n",
       "                \u001b[38;5;66;03m# Decode next token (x-coordinate, or eos)\u001b[39;00m\n",
       "                mask[:, :, pos], pos_ids[\u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m, pos\n",
       "                logits, hidden = self._decode_one_tok(next_emb, mask, pos_ids)\n",
       "                pos += \u001b[32m1\u001b[39m\n",
       "                next_token = torch.argmax(logits, dim=-\u001b[32m1\u001b[39m)\n",
       "\n",
       "        \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
       "\u001b[31mFile:\u001b[39m      /data2/shreyas/ENVS/HF_HOME/modules/transformers_modules/vikhyatk/moondream2/797e1e4728e49ce676920e72e42cd0cb3948f504/moondream.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model._generate_points??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
