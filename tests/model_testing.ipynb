{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e42dc19-1ba2-4c85-baab-05c2f15628f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "825e885f-3955-4c09-a05c-71d1f93b900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, ['<detect>', '<loc0000>', '<loc0001>', '<loc0002>', '<loc0003>'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = ['<detect>',*[f'<loc{v:04d}>' for v in range(1024)]]\n",
    "len(new_tokens), new_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0be73364-facf-4a16-b2f9-1547554af9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-256M-Instruct\", additional_special_tokens=new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e979c50-e1df-4b74-a6a2-50a36af94b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a1c62ec73844ba84674bd8b1ca2905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/7.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404ef36a058b4d139edf5c62aa62a5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7538037e13e4c62a3d317661d73e56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-256M-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f72fe5-9ea1-42da-a970-1abf6c66cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.rand(3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62cb1af6-4d41-4c88-a49b-7f779d00b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=processor(images=[im],do_rescale=False,do_normalize=False,return_tensors='pt',max_image_size={'longest_edge':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "461cfb2e-8349-414b-8a40-7eba966f17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b814f7c9-fbfa-401f-828c-684b150eb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50305, 576, padding_idx=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(processor.tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea2d2818-f8ba-410e-a5d5-504b5b215bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages1 = [{'role': 'user', 'content': [{'type': 'image'}, {'type': 'text', 'text': '<|detect|> person; paddle'}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '<|loc0082|><|loc0137|><|loc1023|><|loc0857|>; person\\n<|loc0537|><|loc0212|><|loc1000|><|loc0440|>; person\\n<|loc0608|><|loc0789|><|loc0913|><|loc0937|>; person\\n<|loc0667|><|loc0742|><|loc0844|><|loc0828|>; person\\n<|loc0105|><|loc0447|><|loc0891|><|loc0969|>; paddle'}]}]\n",
    "messages2 = [{'role': 'user', 'content': [{'type': 'image'}, {'type': 'text', 'text': '<|detect|> person;'}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '<|loc0082|><|loc0137|><|loc1023|><|loc0857|>; person\\n<|loc0537|><|loc0212|><|loc1000|><|loc0440|>; person\\n<|loc0608|><|loc0789|><|loc0913|><|loc0937|>; person'}]}]\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template([messages1, messages2])\n",
    "inputs = processor(text=prompt, images=[im,im], return_tensors=\"pt\",padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54cd430e-cc25-42cf-bf8b-85e32790a414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 17, 3, 512, 512])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e07296c5-9dc9-48da-8b4c-d2b222dd19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1176]), 'right')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape, processor.tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bbc00e6-54ea-4646-be5b-f7e0783cb02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>User:<fake_token_around_image><row_1_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_2_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_3_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_4_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "\n",
      "<fake_token_around_image><global-img><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><|detect|> person; paddle<end_of_utterance>\n",
      "Assistant: <|loc0082|><|loc0137|><|loc1023|><|loc0857|>; person\n",
      "<|loc0537|><|loc0212|><|loc1000|><|loc0440|>; person\n",
      "<|loc0608|><|loc0789|><|loc0913|><|loc0937|>; person\n",
      "<|loc0667|><|loc0742|><|loc0844|><|loc0828|>; person\n",
      "<|loc0105|><|loc0447|><|loc0891|><|loc0969|>; paddle<end_of_utterance>\n",
      "<|im_start|>User:<fake_token_around_image><row_1_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_1_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_2_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_2_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_3_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_3_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "<fake_token_around_image><row_4_col_1><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_2><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_3><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><row_4_col_4><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image>\n",
      "\n",
      "<fake_token_around_image><global-img><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><image><fake_token_around_image><|detect|> person;<end_of_utterance>\n",
      "Assistant: <|loc0082|><|loc0137|><|loc1023|><|loc0857|>; person\n",
      "<|loc0537|><|loc0212|><|loc1000|><|loc0440|>; person\n",
      "<|loc0608|><|loc0789|><|loc0913|><|loc0937|>; person<end_of_utterance>\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.decode(inputs['input_ids'].flatten().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49a256f5-8343-4829-8907-8fea7d39174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>{% for message in messages %}{{message['role'] | capitalize}}{% if message['content'][0]['type'] == 'image' %}{{':'}}{% else %}{{': '}}{% endif %}{% for line in message['content'] %}{% if line['type'] == 'text' %}{{line['text']}}{% elif line['type'] == 'image' %}{{ '<image>' }}{% endif %}{% endfor %}<end_of_utterance>\n",
      "{% endfor %}{% if add_generation_prompt %}{{ 'Assistant:' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(processor.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef982f-6758-4919-9c31-a2ee14d036f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_for_completion_only(samples,response_token='<end_of_utterance>'):\n",
    "    inputs = processor(samples)\n",
    "    labels = inputs['input_ids'].clone()\n",
    "    \n",
    "    assistant_positions = []\n",
    "    assistant_tokens = processor.tokenizer(assistant_template)['input_ids']\n",
    "\n",
    "    for batch_idx in range(inputs['input_ids'].shape[0]):\n",
    "        im_start_positions = torch.where(inputs['input_ids'][batch_idx]==response_token)[0]\n",
    "        labels[]\n",
    "        \n",
    "    for batch_idx in range(inputs['input_ids'].shape[0]):\n",
    "        inputs['labels'][batch_idx, :assistant_positions[batch_idx]-1] = -100\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6d8fe1b9-9653-4006-ba28-5917068d7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples,response_token='<fake_token_around_image>'):\n",
    "    texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "    images = [example[\"image\"] for example in examples]\n",
    "    batch = processor(\n",
    "        text=texts, \n",
    "        images=images, \n",
    "        do_rescale=False,\n",
    "        do_normalize=False,\n",
    "        return_tensors='pt',\n",
    "        max_image_size={'longest_edge':512},\n",
    "        padding=True\n",
    "    )\n",
    "    response_token_id = processor.tokenizer.convert_tokens_to_ids(response_token)\n",
    "\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    batch[\"labels\"] = labels\n",
    "    \n",
    "    for batch_idx in range(inputs['input_ids'].shape[0]):\n",
    "        response_pos = torch.where(inputs['input_ids'][batch_idx]==response_token_id)[0][-1]\n",
    "        batch['labels'][batch_idx, :response_pos+1] = -100\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "91db603a-d88a-4408-871c-902eb8cf0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        'image': torch.rand(3,512,512),\n",
    "        'messages': [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"<detect> obj1; obj2\"}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assitant\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"<loc0000><loc0000><loc0000><loc0000> obj1;\\n<loc0000><loc0000><loc0000><loc0000> obj2\"}\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'image': torch.rand(3,512,512),\n",
    "        'messages': [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": f\"<detect> obj3; obj4\"}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assitant\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"<loc0000><loc0000><loc0000><loc0000> obj3;\\n<loc0000><loc0000><loc0000><loc0000> obj4;\\n<loc0000><loc0000><loc0000><loc0000> obj4\"}\n",
    "                ]\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "14870fdd-1b4f-4149-9e24-65b6015bbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collated = collate_fn(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2d5b60c8-9a22-4aec-9bf3-077f17db7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 49280, 10926, 33, 43, 10926, 34, 49279, 198, 9519, 25963, 42, 216, 49281, 49281, 49281, 49281, 10926, 33, 43, 198, 49281, 49281, 49281, 49281, 10926, 34, 49279, 198, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(collated['labels'][0].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6250514c-a1d7-47ea-b300-ca095fc6fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<detect> obj1; obj2<end_of_utterance>\n",
      "Assitant: <loc0000><loc0000><loc0000><loc0000> obj1;\n",
      "<loc0000><loc0000><loc0000><loc0000> obj2<end_of_utterance>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(processor.tokenizer.decode([t for t in collated['labels'][0].numpy().tolist() if t!=-100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d63e7731-962b-4a8a-82b8-4550a3b0fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce723e4c-0ab0-42e3-8583-d47493f46f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values', 'pixel_attention_mask', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9c6250bb-ad28-4c9d-a8f5-bdc4ec21193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98d3619b-6e05-4930-b61f-66e779a81a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Idefics3ForConditionalGeneration(\n",
       "  (model): Idefics3Model(\n",
       "    (vision_model): Idefics3VisionTransformer(\n",
       "      (embeddings): Idefics3VisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), padding=valid)\n",
       "        (position_embedding): Embedding(1024, 768)\n",
       "      )\n",
       "      (encoder): Idefics3Encoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x Idefics3EncoderLayer(\n",
       "            (self_attn): Idefics3VisionAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Idefics3VisionMLP(\n",
       "              (activation_fn): PytorchGELUTanh()\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (connector): Idefics3Connector(\n",
       "      (modality_projection): Idefics3SimpleMLP(\n",
       "        (proj): Linear(in_features=12288, out_features=576, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (text_model): LlamaModel(\n",
       "      (embed_tokens): Embedding(50305, 576, padding_idx=2)\n",
       "      (layers): ModuleList(\n",
       "        (0-29): 30 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "            (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "            (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "            (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "            (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "            (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=576, out_features=50305, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a01ade89-844e-4299-b506-536f31d179e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['q_proj','k_proj','v_proj','out_proj','gate_proj','up_proj','down_proj','embed_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c3e78ee7-706a-4518-9c3e-05b0a8fcab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=16,\n",
    "    target_modules=targets,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7fb0167e-2301-4e40-972a-fefde440cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 50,602,112 || all params: 308,267,840 || trainable%: 16.4150\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e63fc0d0-e712-47b7-b72f-bd067a39b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = SFTConfig(\n",
    "    output_dir='./VLM_OD',\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.25,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.2,\n",
    "    logging_steps=500,\n",
    "    save_steps=500,\n",
    "    bf16=True,\n",
    "    do_eval=False,\n",
    "    push_to_hub=False,\n",
    "    report_to='none',\n",
    "    dataset_num_proc=4,\n",
    "    save_total_limit=1,\n",
    "    dataset_kwargs={'skip_prepare_dataset': True},\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9f1d8-190d-423c-9f17-fc3e2ce1cd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
